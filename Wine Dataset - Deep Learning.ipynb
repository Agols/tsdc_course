{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73f54613-2467-4491-a9c4-8c0d4b8fa250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.18.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Concatenate, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Accuracy\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cufflinks as cf; cf.go_offline()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7da0ba18-6139-45e9-84c3-cf52bda0d3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "74793baa-90e6-4355-9c14-732e1a3c37d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119924, 8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_reviews = pd.read_csv(\"data/wine_reviews.csv\", index_col=0)\n",
    "wine_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb76c8e0-a456-473c-87e2-9e1a359190ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['country', 'description', 'points', 'price', 'province', 'taster_name',\n",
       "       'variety', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_reviews.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "752ec0c1-c9d1-46d8-82ed-72b91745de4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_reviews.variety.fillna(\"NA\", inplace=True)\n",
    "wine_reviews.taster_name.fillna(\"NA\", inplace=True)\n",
    "wine_reviews.year.fillna(wine_reviews.year.min(),inplace=True)\n",
    "wine_reviews.price.fillna(wine_reviews.price.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d3b5119-06df-4f2f-9ec3-1a0c32c168f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>variety</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115411</th>\n",
       "      <td>US</td>\n",
       "      <td>Fruity and forward with ripe blackberry and ch...</td>\n",
       "      <td>88</td>\n",
       "      <td>25.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>Anna Lee C. Iijima</td>\n",
       "      <td>Red Blend</td>\n",
       "      <td>2010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109678</th>\n",
       "      <td>US</td>\n",
       "      <td>Menthol and pepper ride over dark cherry and s...</td>\n",
       "      <td>85</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>Alexander Peartree</td>\n",
       "      <td>Bordeaux-style Red Blend</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53765</th>\n",
       "      <td>Germany</td>\n",
       "      <td>Sharp acidity offsets juicy white peach and ap...</td>\n",
       "      <td>90</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Pfalz</td>\n",
       "      <td>Anna Lee C. Iijima</td>\n",
       "      <td>Riesling</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31885</th>\n",
       "      <td>US</td>\n",
       "      <td>Concannon's Reserve Petite swirls in plum, dar...</td>\n",
       "      <td>87</td>\n",
       "      <td>40.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Virginie Boone</td>\n",
       "      <td>Petite Sirah</td>\n",
       "      <td>2008.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107120</th>\n",
       "      <td>Italy</td>\n",
       "      <td>A blend of 60% Sangiovese and 40% Cabernet Sau...</td>\n",
       "      <td>89</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Tuscany</td>\n",
       "      <td>Kerin O’Keefe</td>\n",
       "      <td>Red Blend</td>\n",
       "      <td>2009.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        country                                        description  points  \\\n",
       "115411       US  Fruity and forward with ripe blackberry and ch...      88   \n",
       "109678       US  Menthol and pepper ride over dark cherry and s...      85   \n",
       "53765   Germany  Sharp acidity offsets juicy white peach and ap...      90   \n",
       "31885        US  Concannon's Reserve Petite swirls in plum, dar...      87   \n",
       "107120    Italy  A blend of 60% Sangiovese and 40% Cabernet Sau...      89   \n",
       "\n",
       "        price    province         taster_name                   variety  \\\n",
       "115411   25.0    New York  Anna Lee C. Iijima                 Red Blend   \n",
       "109678   20.0    Virginia  Alexander Peartree  Bordeaux-style Red Blend   \n",
       "53765    19.0       Pfalz  Anna Lee C. Iijima                  Riesling   \n",
       "31885    40.0  California      Virginie Boone              Petite Sirah   \n",
       "107120   65.0     Tuscany       Kerin O’Keefe                 Red Blend   \n",
       "\n",
       "          year  \n",
       "115411  2010.0  \n",
       "109678  2013.0  \n",
       "53765   2015.0  \n",
       "31885   2008.0  \n",
       "107120  2009.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_reviews.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96ca5f65-3fba-4c12-ab3b-007080c46b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>variety</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [country, description, points, price, province, taster_name, variety, year]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_reviews[wine_reviews.year.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "21bee2d0-9499-4461-80e5-b5b944c3530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_col = ['description']\n",
    "price_col_name = 'price'\n",
    "numerical_col = [price_col_name]\n",
    "categorical_col = ['country','province','taster_name','variety','year']\n",
    "\n",
    "X = wine_reviews[['description','price','country','province','taster_name','variety', 'year']].copy()\n",
    "y = wine_reviews['points'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "67ee88c6-768f-4ea5-8dae-4b0c4d59c723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical features to one-hot encoding\n",
    "for col in categorical_col:\n",
    "    X[col] = pd.Categorical(X[col])\n",
    "    X[col] = X[col].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6ae63434-ef52-46d9-a727-5c7f8dd39b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>country</th>\n",
       "      <th>province</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>variety</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102242</th>\n",
       "      <td>New leather, wild berry, violet, white pepper ...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>22</td>\n",
       "      <td>286</td>\n",
       "      <td>9</td>\n",
       "      <td>382</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127785</th>\n",
       "      <td>Pungent aromas of field greens and citrus lead...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15</td>\n",
       "      <td>195</td>\n",
       "      <td>14</td>\n",
       "      <td>511</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51628</th>\n",
       "      <td>From a very good if not great Champagne vintag...</td>\n",
       "      <td>139.0</td>\n",
       "      <td>15</td>\n",
       "      <td>75</td>\n",
       "      <td>16</td>\n",
       "      <td>121</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16233</th>\n",
       "      <td>Aromas include dry apricot and papaya with a h...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>37</td>\n",
       "      <td>132</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76913</th>\n",
       "      <td>Produced in partnership between Schulz Cellars...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>40</td>\n",
       "      <td>51</td>\n",
       "      <td>19</td>\n",
       "      <td>223</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              description  price  country  \\\n",
       "102242  New leather, wild berry, violet, white pepper ...   58.0       22   \n",
       "127785  Pungent aromas of field greens and citrus lead...   19.0       15   \n",
       "51628   From a very good if not great Champagne vintag...  139.0       15   \n",
       "16233   Aromas include dry apricot and papaya with a h...   18.0       37   \n",
       "76913   Produced in partnership between Schulz Cellars...   18.0       40   \n",
       "\n",
       "        province  taster_name  variety  year  \n",
       "102242       286            9      382    71  \n",
       "127785       195           14      511    60  \n",
       "51628         75           16      121    67  \n",
       "16233        132           12        7    71  \n",
       "76913         51           19      223    72  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcc23543-19b7-4dd3-841d-c9515a6ebd5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1821.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.year.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c299890b-28a7-4be3-be06-def8143f749f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>country</th>\n",
       "      <th>province</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>variety</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [description, price, country, province, taster_name, variety, year]\n",
       "Index: []"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[X.year.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "50596aac-d6e9-41e5-9a22-483bc118243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['price'] = np.log(X['price'])\n",
    "scaler = StandardScaler()\n",
    "X[['price']] = scaler.fit_transform(X[['price']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec4c24a1-bf69-4373-830b-733273d7b917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>country</th>\n",
       "      <th>province</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>variety</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11208</th>\n",
       "      <td>Very terroir-driven from chalk soil in this gr...</td>\n",
       "      <td>2.384253</td>\n",
       "      <td>15</td>\n",
       "      <td>47</td>\n",
       "      <td>16</td>\n",
       "      <td>437</td>\n",
       "      <td>2011.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26805</th>\n",
       "      <td>Tangy and showing some good aging, this is a r...</td>\n",
       "      <td>-0.052160</td>\n",
       "      <td>31</td>\n",
       "      <td>294</td>\n",
       "      <td>16</td>\n",
       "      <td>446</td>\n",
       "      <td>1821.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121534</th>\n",
       "      <td>A new wine for Aegerter, this is ripe and full...</td>\n",
       "      <td>-0.838306</td>\n",
       "      <td>15</td>\n",
       "      <td>183</td>\n",
       "      <td>16</td>\n",
       "      <td>125</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121029</th>\n",
       "      <td>Toffee, exotic spice, vanilla, raspberry and c...</td>\n",
       "      <td>0.734930</td>\n",
       "      <td>40</td>\n",
       "      <td>411</td>\n",
       "      <td>17</td>\n",
       "      <td>696</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43754</th>\n",
       "      <td>This wine is dense, tough and dark—a black plu...</td>\n",
       "      <td>-0.052160</td>\n",
       "      <td>31</td>\n",
       "      <td>294</td>\n",
       "      <td>16</td>\n",
       "      <td>446</td>\n",
       "      <td>2010.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              description     price  country  \\\n",
       "11208   Very terroir-driven from chalk soil in this gr...  2.384253       15   \n",
       "26805   Tangy and showing some good aging, this is a r... -0.052160       31   \n",
       "121534  A new wine for Aegerter, this is ripe and full... -0.838306       15   \n",
       "121029  Toffee, exotic spice, vanilla, raspberry and c...  0.734930       40   \n",
       "43754   This wine is dense, tough and dark—a black plu... -0.052160       31   \n",
       "\n",
       "        province  taster_name  variety    year  \n",
       "11208         47           16      437  2011.0  \n",
       "26805        294           16      446  1821.0  \n",
       "121534       183           16      125  2013.0  \n",
       "121029       411           17      696  2012.0  \n",
       "43754        294           16      446  2010.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce3fa575-ead2-4c10-b382-c45b0f52c163",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7cb0e65d-3ed4-46f0-97e9-3e92ad37dddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_len = wine_reviews.country.nunique()\n",
    "province_len = wine_reviews.province.nunique()\n",
    "tester_len = wine_reviews.taster_name.nunique()\n",
    "variety_len = wine_reviews.variety.nunique()\n",
    "year_len  = wine_reviews.year.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39beff1-76dd-4e15-95f9-ba08c2904a1d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model without textual columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53c64c5c-8738-4b57-abea-05b0c0cf2a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country:43  province 425  tester 20  variety 701  year 78\n"
     ]
    }
   ],
   "source": [
    "print(f'country:{country_len}  province {province_len}  tester {tester_len}  variety {variety_len}  year {year_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23869006-e4a7-4541-8b7f-751675ba7c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the graph model\n",
    "# Categorical inputs\n",
    "# country\n",
    "cat_input_country = Input(shape=(1,))\n",
    "embedding_country = Embedding(input_dim=country_len, output_dim=7)(cat_input_country)\n",
    "flat_embed_country = Flatten()(embedding_country)\n",
    "\n",
    "#province\n",
    "cat_input_province = Input(shape=(1,))\n",
    "embedding_province = Embedding(input_dim=province_len, output_dim=22)(cat_input_province)\n",
    "flat_embed_province = Flatten()(embedding_province)\n",
    "\n",
    "#taster_name\n",
    "cat_input_tester = Input(shape=(1,))\n",
    "embedding_tester = Embedding(input_dim=tester_len, output_dim=5)(cat_input_tester)\n",
    "flat_embed_tester = Flatten()(embedding_tester)\n",
    "\n",
    "#variety\n",
    "cat_input_variety = Input(shape=(1,))\n",
    "embedding_variety = Embedding(input_dim=variety_len, output_dim=30)(cat_input_variety)\n",
    "flat_embed_variety = Flatten()(embedding_variety)\n",
    "\n",
    "#year\n",
    "cat_input_year = Input(shape=(1,))\n",
    "embedding_year = Embedding(input_dim=year_len, output_dim=9)(cat_input_year)\n",
    "flat_embed_year = Flatten()(embedding_year)\n",
    "\n",
    "\n",
    "# Numerical inputs\n",
    "num_input = Input(shape=(1,))\n",
    "\n",
    "# Concatenate categorical embeddings with numerical inputs\n",
    "concatenated = Concatenate()([flat_embed_country, flat_embed_province, flat_embed_tester, flat_embed_variety, num_input])\n",
    "#concatenated = Concatenate()([flat_embed_country, flat_embed_province, flat_embed_tester, flat_embed_variety, flat_embed_year, num_input])\n",
    "\n",
    "\n",
    "# Dense layers for classification\n",
    "x = Dense(16, activation='relu')(concatenated)\n",
    "x = Dense(8, activation='relu')(x)\n",
    "outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[cat_input_country, cat_input_province, cat_input_tester, cat_input_variety, num_input], outputs=outputs)\n",
    "#model = Model(inputs=[cat_input_country, cat_input_province, cat_input_tester, cat_input_variety, cat_input_year, num_input], outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e05ce26f-dbb0-434d-b8b1-908d0b9b6ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b495a8ae-f825-4d2a-88db-2829fcf3e348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, show_dtype=True, show_shapes=True, show_layer_names=True, to_file='model_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a2fc42-f039-4e03-82e9-6e7aab17a8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "categorical_col = ['country','province','taster_name','variety']\n",
    "\n",
    "train_X_data = [X_train['country'], X_train['province'], X_train['taster_name'], X_train['variety'], X_train[[price_col_name]]]\n",
    "#train_X_data = [X_train['country'], X_train['province'], X_train['taster_name'], X_train['variety'], X_train[[price_col_name]]]\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.01),\n",
    "              loss='mean_squared_error',\n",
    "              metrics=[Accuracy()])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_X_data, y_train,\n",
    "          batch_size=64,\n",
    "          epochs=10)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(train_X_data, y_train)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03301a89-589d-4227-b08a-0a4a804c033d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2999/2999 [==============================] - 3s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_train_actual = model.predict(train_X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "37def814-a0b9-4bde-842f-98a618bbbab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "test_X_data = [X_test['country'], X_test['province'], X_test['taster_name'], X_test['variety'], X_test[[price_col_name, 'year']]]\n",
    "y_test_actual = model.predict(test_X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "edb64f9a-efd5-4ca3-9dc7-e86ecdc46fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error train: 9.64\n",
      "R2: -0.01 train\n",
      "Mean squared error test: 8073.05\n",
      "R2: -842.96 test\n"
     ]
    }
   ],
   "source": [
    "mse_train = mean_squared_error(y_train, y_train_actual)\n",
    "r2_train = r2_score(y_train, y_train_actual)\n",
    "mse_test = mean_squared_error(y_test, y_test_actual)\n",
    "r2_test = r2_score(y_test, y_test_actual)\n",
    "print(\"Mean squared error train: %.2f\" % mse_train)\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print(\"R2: %.2f train\" % r2_train)\n",
    "print(\"Mean squared error test: %.2f\" % mse_test)\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print(\"R2: %.2f test\" % r2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8a8c124c-c8d2-445b-8a16-e4dcfa1136b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "      <th>price</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114972</th>\n",
       "      <td>100</td>\n",
       "      <td>-1.369088</td>\n",
       "      <td>4.975731</td>\n",
       "      <td>101.369088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123545</th>\n",
       "      <td>100</td>\n",
       "      <td>-1.367253</td>\n",
       "      <td>1.684146</td>\n",
       "      <td>101.367253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111758</th>\n",
       "      <td>99</td>\n",
       "      <td>-1.383423</td>\n",
       "      <td>-0.143399</td>\n",
       "      <td>100.383423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116094</th>\n",
       "      <td>99</td>\n",
       "      <td>-1.383141</td>\n",
       "      <td>-0.143399</td>\n",
       "      <td>100.383141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118059</th>\n",
       "      <td>99</td>\n",
       "      <td>-1.375552</td>\n",
       "      <td>0.744823</td>\n",
       "      <td>100.375552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47894</th>\n",
       "      <td>99</td>\n",
       "      <td>-1.373672</td>\n",
       "      <td>1.582743</td>\n",
       "      <td>100.373672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114973</th>\n",
       "      <td>99</td>\n",
       "      <td>-1.373182</td>\n",
       "      <td>3.583668</td>\n",
       "      <td>100.373182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45573</th>\n",
       "      <td>99</td>\n",
       "      <td>-1.367248</td>\n",
       "      <td>2.914020</td>\n",
       "      <td>100.367248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79104</th>\n",
       "      <td>99</td>\n",
       "      <td>-1.366719</td>\n",
       "      <td>3.474429</td>\n",
       "      <td>100.366719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56043</th>\n",
       "      <td>99</td>\n",
       "      <td>-1.364150</td>\n",
       "      <td>4.311846</td>\n",
       "      <td>100.364150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        actual  predicted     price       error\n",
       "114972     100  -1.369088  4.975731  101.369088\n",
       "123545     100  -1.367253  1.684146  101.367253\n",
       "111758      99  -1.383423 -0.143399  100.383423\n",
       "116094      99  -1.383141 -0.143399  100.383141\n",
       "118059      99  -1.375552  0.744823  100.375552\n",
       "47894       99  -1.373672  1.582743  100.373672\n",
       "114973      99  -1.373182  3.583668  100.373182\n",
       "45573       99  -1.367248  2.914020  100.367248\n",
       "79104       99  -1.366719  3.474429  100.366719\n",
       "56043       99  -1.364150  4.311846  100.364150"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_df1 = pd.DataFrame()\n",
    "predicted_df1[\"actual\"] = y_test\n",
    "predicted_df1[\"predicted\"] = y_test_actual\n",
    "predicted_df1[\"price\"] = X_test.price\n",
    "predicted_df1['error'] = abs(predicted_df1[\"actual\"] - predicted_df1['predicted'])\n",
    "predicted_df1.sort_values(by=\"error\", ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "188ee0b1-87f0-4c39-bff9-0bd7e37ff8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "      <th>price</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24646</th>\n",
       "      <td>87</td>\n",
       "      <td>50.298290</td>\n",
       "      <td>-1.583078</td>\n",
       "      <td>36.701710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45798</th>\n",
       "      <td>100</td>\n",
       "      <td>88.212967</td>\n",
       "      <td>3.123825</td>\n",
       "      <td>11.787033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111754</th>\n",
       "      <td>100</td>\n",
       "      <td>88.212967</td>\n",
       "      <td>3.595350</td>\n",
       "      <td>11.787033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42197</th>\n",
       "      <td>100</td>\n",
       "      <td>88.212967</td>\n",
       "      <td>4.397961</td>\n",
       "      <td>11.787033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7335</th>\n",
       "      <td>100</td>\n",
       "      <td>88.212967</td>\n",
       "      <td>3.200484</td>\n",
       "      <td>11.787033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>100</td>\n",
       "      <td>88.212967</td>\n",
       "      <td>4.003095</td>\n",
       "      <td>11.787033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111756</th>\n",
       "      <td>100</td>\n",
       "      <td>88.212967</td>\n",
       "      <td>4.042987</td>\n",
       "      <td>11.787033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111753</th>\n",
       "      <td>100</td>\n",
       "      <td>88.212967</td>\n",
       "      <td>6.289646</td>\n",
       "      <td>11.787033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118058</th>\n",
       "      <td>100</td>\n",
       "      <td>88.212967</td>\n",
       "      <td>4.397961</td>\n",
       "      <td>11.787033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39286</th>\n",
       "      <td>100</td>\n",
       "      <td>88.212967</td>\n",
       "      <td>4.432494</td>\n",
       "      <td>11.787033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113929</th>\n",
       "      <td>100</td>\n",
       "      <td>88.212967</td>\n",
       "      <td>1.684146</td>\n",
       "      <td>11.787033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111755</th>\n",
       "      <td>100</td>\n",
       "      <td>88.212967</td>\n",
       "      <td>6.289646</td>\n",
       "      <td>11.787033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89728</th>\n",
       "      <td>100</td>\n",
       "      <td>88.212967</td>\n",
       "      <td>3.474429</td>\n",
       "      <td>11.787033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58352</th>\n",
       "      <td>100</td>\n",
       "      <td>88.212967</td>\n",
       "      <td>2.671818</td>\n",
       "      <td>11.787033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89729</th>\n",
       "      <td>100</td>\n",
       "      <td>88.212967</td>\n",
       "      <td>4.893866</td>\n",
       "      <td>11.787033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122935</th>\n",
       "      <td>100</td>\n",
       "      <td>88.212967</td>\n",
       "      <td>5.393527</td>\n",
       "      <td>11.787033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45781</th>\n",
       "      <td>100</td>\n",
       "      <td>88.212967</td>\n",
       "      <td>4.713255</td>\n",
       "      <td>11.787033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36528</th>\n",
       "      <td>100</td>\n",
       "      <td>88.212967</td>\n",
       "      <td>3.529998</td>\n",
       "      <td>11.787033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39287</th>\n",
       "      <td>99</td>\n",
       "      <td>88.212967</td>\n",
       "      <td>3.862296</td>\n",
       "      <td>10.787033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44994</th>\n",
       "      <td>99</td>\n",
       "      <td>88.212967</td>\n",
       "      <td>4.836820</td>\n",
       "      <td>10.787033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        actual  predicted     price      error\n",
       "24646       87  50.298290 -1.583078  36.701710\n",
       "45798      100  88.212967  3.123825  11.787033\n",
       "111754     100  88.212967  3.595350  11.787033\n",
       "42197      100  88.212967  4.397961  11.787033\n",
       "7335       100  88.212967  3.200484  11.787033\n",
       "345        100  88.212967  4.003095  11.787033\n",
       "111756     100  88.212967  4.042987  11.787033\n",
       "111753     100  88.212967  6.289646  11.787033\n",
       "118058     100  88.212967  4.397961  11.787033\n",
       "39286      100  88.212967  4.432494  11.787033\n",
       "113929     100  88.212967  1.684146  11.787033\n",
       "111755     100  88.212967  6.289646  11.787033\n",
       "89728      100  88.212967  3.474429  11.787033\n",
       "58352      100  88.212967  2.671818  11.787033\n",
       "89729      100  88.212967  4.893866  11.787033\n",
       "122935     100  88.212967  5.393527  11.787033\n",
       "45781      100  88.212967  4.713255  11.787033\n",
       "36528      100  88.212967  3.529998  11.787033\n",
       "39287       99  88.212967  3.862296  10.787033\n",
       "44994       99  88.212967  4.836820  10.787033"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_df = pd.DataFrame()\n",
    "predicted_df[\"actual\"] = y_train\n",
    "predicted_df[\"predicted\"] = y_train_actual\n",
    "predicted_df[\"price\"] = X_train.price\n",
    "predicted_df['error'] = abs(predicted_df[\"actual\"] - predicted_df['predicted'])\n",
    "predicted_df.sort_values(by=\"error\", ascending=False).head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6dcae0b3-e742-44a0-a6af-a9edfa57ea23",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=['name','classifier','alpha','reduction','train_r2','train_mse', 'test_r2', 'test_mse'])\n",
    "\n",
    "def append_to_results(name, classifier, alpha, reduction, y_test, y_predict, y_train, y_train_predicted):\n",
    "    test_r2 = r2_score(y_test, y_predicted), \n",
    "    test_mse = mean_squared_error(y_test, y_predicted)\n",
    "    train_r2 = r2_score(y_train, y_train_predicted)\n",
    "    train_mse = mean_squared_error(y_train, y_train_predicted)\n",
    "    \n",
    "    return results_df.append({'name':name, 'classifier':classifier, 'alpha': alpha, 'reduction':reduction, 'test_r2': test_r2, 'test_mse':test_mse, 'train_r2': train_r2, \"train_mse\": train_mse}, ignore_index=True)\n",
    "\n",
    "def append_row_to_results(name, classifier, alpha, reduction, test_r2, test_mse, train_r2, train_mse):\n",
    "    return results_df.append({'name':name, 'classifier':classifier, 'alpha': alpha, 'reduction':reduction, 'test_r2': test_r2, 'test_mse':test_mse, 'train_r2': train_r2, \"train_mse\": train_mse}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98b046a-9511-45dc-81e4-360aa8ee8367",
   "metadata": {},
   "outputs": [],
   "source": [
    "append_to_results(\"Deep Learning, categorial and numerical features\", "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e84770-affa-4f5f-a9f4-dc973120cec3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model With Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "47790cff-7d14-40e6-b161-27b68bd0c0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization # after TensorFlow 2.6\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5513a058-320d-41c4-8a83-7bfc841583a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "08aad5f5-e23b-4d37-992a-c09186109b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>country</th>\n",
       "      <th>province</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>variety</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28171</th>\n",
       "      <td>This falls sbetween a rosé and an orange wine ...</td>\n",
       "      <td>0.034663</td>\n",
       "      <td>40</td>\n",
       "      <td>268</td>\n",
       "      <td>15</td>\n",
       "      <td>433</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25907</th>\n",
       "      <td>Tight and structured, this wine has minerality...</td>\n",
       "      <td>-0.659546</td>\n",
       "      <td>15</td>\n",
       "      <td>47</td>\n",
       "      <td>16</td>\n",
       "      <td>125</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86353</th>\n",
       "      <td>Prominent yet not overpowering oak smoke aroma...</td>\n",
       "      <td>-0.143399</td>\n",
       "      <td>40</td>\n",
       "      <td>51</td>\n",
       "      <td>11</td>\n",
       "      <td>125</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87206</th>\n",
       "      <td>This wine is made to be enjoyed young and frui...</td>\n",
       "      <td>-1.170851</td>\n",
       "      <td>31</td>\n",
       "      <td>108</td>\n",
       "      <td>16</td>\n",
       "      <td>447</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91790</th>\n",
       "      <td>Just too raisiny and stewed for real satisfact...</td>\n",
       "      <td>-0.417344</td>\n",
       "      <td>40</td>\n",
       "      <td>51</td>\n",
       "      <td>14</td>\n",
       "      <td>325</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             description     price  country  \\\n",
       "28171  This falls sbetween a rosé and an orange wine ...  0.034663       40   \n",
       "25907  Tight and structured, this wine has minerality... -0.659546       15   \n",
       "86353  Prominent yet not overpowering oak smoke aroma... -0.143399       40   \n",
       "87206  This wine is made to be enjoyed young and frui... -1.170851       31   \n",
       "91790  Just too raisiny and stewed for real satisfact... -0.417344       40   \n",
       "\n",
       "       province  taster_name  variety  year  \n",
       "28171       268           15      433    74  \n",
       "25907        47           16      125    74  \n",
       "86353        51           11      125    72  \n",
       "87206       108           16      447    73  \n",
       "91790        51           14      325    64  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d7f012af-439b-440a-add8-4f3f0ad4313a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_length = 11000 # max words to have in vocabulary\n",
    "max_length = 40 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
    "                                    output_mode=\"int\",\n",
    "                                    output_sequence_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f549d17d-3b63-45de-8918-04ffcc15c032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.embedding.Embedding at 0x17be92be0a0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
    "                             output_dim=128, # set size of embedding vector\n",
    "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
    "                             input_length=max_length, #how long is each input\n",
    "                             name=\"embedding_1\") \n",
    "\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d6351f2d-3dcd-41c7-9af2-13ee72ab5de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_28 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_23 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_24 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_25 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_26 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " text_vectorization_1 (TextVect  (None, 40)          0           ['input_28[0][0]']               \n",
      " orization)                                                                                       \n",
      "                                                                                                  \n",
      " embedding_15 (Embedding)       (None, 1, 7)         301         ['input_23[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_16 (Embedding)       (None, 1, 22)        9350        ['input_24[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_17 (Embedding)       (None, 1, 5)         100         ['input_25[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_18 (Embedding)       (None, 1, 30)        21030       ['input_26[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 40, 128)      1408000     ['text_vectorization_1[3][0]']   \n",
      "                                                                                                  \n",
      " flatten_15 (Flatten)           (None, 7)            0           ['embedding_15[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_16 (Flatten)           (None, 22)           0           ['embedding_16[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_17 (Flatten)           (None, 5)            0           ['embedding_17[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_18 (Flatten)           (None, 30)           0           ['embedding_18[0][0]']           \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  (None, 64)           49408       ['embedding_1[3][0]']            \n",
      "                                                                                                  \n",
      " input_29 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 129)          0           ['flatten_15[0][0]',             \n",
      "                                                                  'flatten_16[0][0]',             \n",
      "                                                                  'flatten_17[0][0]',             \n",
      "                                                                  'flatten_18[0][0]',             \n",
      "                                                                  'lstm_2[0][0]',                 \n",
      "                                                                  'input_29[0][0]']               \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 16)           2080        ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 8)            136         ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 1)            9           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,490,414\n",
      "Trainable params: 1,490,414\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the graph model\n",
    "# Categorical inputs\n",
    "# country\n",
    "cat_input_country = Input(shape=(1,))\n",
    "embedding_country = Embedding(input_dim=country_len, output_dim=7)(cat_input_country)\n",
    "flat_embed_country = Flatten()(embedding_country)\n",
    "\n",
    "#province\n",
    "cat_input_province = Input(shape=(1,))\n",
    "embedding_province = Embedding(input_dim=province_len, output_dim=22)(cat_input_province)\n",
    "flat_embed_province = Flatten()(embedding_province)\n",
    "\n",
    "#taster_name\n",
    "cat_input_tester = Input(shape=(1,))\n",
    "embedding_tester = Embedding(input_dim=tester_len, output_dim=5)(cat_input_tester)\n",
    "flat_embed_tester = Flatten()(embedding_tester)\n",
    "\n",
    "#variety\n",
    "cat_input_variety = Input(shape=(1,))\n",
    "embedding_variety = Embedding(input_dim=variety_len, output_dim=30)(cat_input_variety)\n",
    "flat_embed_variety = Flatten()(embedding_variety)\n",
    "\n",
    "#year\n",
    "cat_input_year = Input(shape=(1,))\n",
    "embedding_year = Embedding(input_dim=year_len, output_dim=9)(cat_input_year)\n",
    "flat_embed_year = Flatten()(embedding_year)\n",
    "\n",
    "#text\n",
    "text_input = Input(shape=(1,), dtype=\"string\")\n",
    "\n",
    "text_vector = text_vectorizer(text_input)\n",
    "text_embedding = embedding(text_vector)\n",
    "text_embedding = layers.LSTM(64)(text_embedding)\n",
    "\n",
    "\n",
    "# Numerical inputs\n",
    "num_input = Input(shape=(1,))\n",
    "\n",
    "# Concatenate categorical embeddings with numerical inputs\n",
    "concatenated = Concatenate()([flat_embed_country, flat_embed_province, flat_embed_tester, flat_embed_variety, text_embedding, num_input])\n",
    "#concatenated = Concatenate()([flat_embed_country, flat_embed_province, flat_embed_tester, flat_embed_variety, flat_embed_year, num_input])\n",
    "\n",
    "\n",
    "# Dense layers for classification\n",
    "x = Dense(16, activation='relu')(concatenated)\n",
    "x = Dense(8, activation='relu')(x)\n",
    "outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[cat_input_country, cat_input_province, cat_input_tester, cat_input_variety, text_input, num_input], outputs=outputs)\n",
    "#model = Model(inputs=[cat_input_country, cat_input_province, cat_input_tester, cat_input_variety, cat_input_year, num_input], outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "66a437d4-e308-44c7-b634-3a68c311b96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.mse,\n",
    "                          optimizer=tf.keras.optimizers.Adam(),\n",
    "                          metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a376e0-fb54-46c8-ac05-78ece10aeca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_data = [X_train['country'], X_train['province'], X_train['taster_name'], X_train['variety'], np.array(X_train['description']), X_train[[price_col_name]]]\n",
    "#train_X_data = [X_train['country'], X_train['province'], X_train['taster_name'], X_train['variety'], X_train[[price_col_name]]]\n",
    "\n",
    "#model.compile(optimizer=Adam(learning_rate=0.01),loss='mean_squared_error',metrics=[Accuracy()])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_X_data, y_train,\n",
    "          batch_size=64,\n",
    "          epochs=10)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(train_X_data, y_train)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bb0533-841c-4903-86e6-0264972939c9",
   "metadata": {},
   "source": [
    "## Try very simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e4736fec-eb58-4cb4-a145-d9598bf97f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_73 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " embedding_59 (Embedding)       (None, 1, 8)         5608        ['input_73[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_59 (Flatten)           (None, 8)            0           ['embedding_59[0][0]']           \n",
      "                                                                                                  \n",
      " input_74 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate_13 (Concatenate)   (None, 9)            0           ['flatten_59[0][0]',             \n",
      "                                                                  'input_74[0][0]']               \n",
      "                                                                                                  \n",
      " dense_39 (Dense)               (None, 32)           320         ['concatenate_13[0][0]']         \n",
      "                                                                                                  \n",
      " dense_40 (Dense)               (None, 16)           528         ['dense_39[0][0]']               \n",
      "                                                                                                  \n",
      " dense_41 (Dense)               (None, 1)            17          ['dense_40[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,473\n",
      "Trainable params: 6,473\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#variety\n",
    "cat_input_variety = Input(shape=(1,))\n",
    "embedding_variety = Embedding(input_dim=X.variety.nunique(), output_dim=8)(cat_input_variety)\n",
    "flat_embed_variety = Flatten()(embedding_variety)\n",
    "\n",
    "# Numerical inputs\n",
    "num_input = Input(shape=(1,))\n",
    "\n",
    "# Concatenate categorical embeddings with numerical inputs\n",
    "concatenated = Concatenate()([flat_embed_variety, num_input])\n",
    "\n",
    "# Dense layers for classification\n",
    "x = Dense(32, activation='tanh')(concatenated)\n",
    "x = Dense(16, activation='tanh')(x)\n",
    "outputs = Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[cat_input_variety, num_input], outputs=outputs)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d16603d-cf26-4e81-9e7d-27eadd98cea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[104748    703\n",
       " 101219    561\n",
       " 82261      80\n",
       " 36717     705\n",
       " 128031     62\n",
       "          ... \n",
       " 128106    480\n",
       " 103694    430\n",
       " 860        71\n",
       " 15795      62\n",
       " 121958    474\n",
       " Name: variety, Length: 103976, dtype: int16,\n",
       " 104748   -0.312389\n",
       " 101219   -0.261854\n",
       " 82261     4.791597\n",
       " 36717    -0.590329\n",
       " 128031   -0.312389\n",
       "             ...   \n",
       " 128106   -0.489260\n",
       " 103694   -0.135518\n",
       " 860       0.243491\n",
       " 15795     2.896553\n",
       " 121958    0.041353\n",
       " Name: price, Length: 103976, dtype: float64]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [X_train['variety'], X_train[numeric_col_name]]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6015e0ae-bfae-4c72-8c00-015c0b53352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.head(100000) \n",
    "\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss='mean_squared_error',\n",
    "              metrics=[Accuracy()])\n",
    "data = [X_train_small[ X_train_small['variety'],  X_train_small[numerical_col]]]\n",
    "# Train the model\n",
    "model.fit( data, y_train.head(100000),\n",
    "          batch_size=16,\n",
    "          epochs=10)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(data, y_train.head(100000))\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ecc3a3-2658-4576-b6bb-17eff696d3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea441346-e599-4713-83ac-3bdd78917d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertModel, RobertaModel, RobertaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f16e7f-5381-40ab-b7fc-b195d7fa3033",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# Text to vectorize\n",
    "text = \"Here is an example paragraph that we will convert into an embedding.\"\n",
    "\n",
    "# Add special tokens for BERT (start and end of sentence)\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "# Tokenize our sentence\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "# Map tokens to their index in the tokenizer vocabulary\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "# Convert list to torch tensor\n",
    "  = torch.tensor([indexed_tokens])\n",
    "\n",
    "# Put everything on the GPU if available and run through the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tokens_tensor = tokens_tensor.to(device)\n",
    "model = model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(tokens_tensor)\n",
    "    # The first element of outputs is the last layer of the model, which can be used as embeddings.\n",
    "    embeddings = outputs[0]\n",
    "\n",
    "# Calculate the mean to get sentence vector\n",
    "mean_embeddings = torch.mean(embeddings, dim=1).cpu().numpy()\n",
    "\n",
    "print(mean_embeddings.flatten()[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395eee24-1863-4a59-be1e-ecf9a80cef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install \"torch>=2.0\" --extra-index-url https://download.pytorch.org/whl/cu117 --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63fa188-9ee4-4313-8e2f-c4a15fc425b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install \"transformers==4.27.1\" \"datasets==2.9.0\" \"accelerate==0.17.1\" \"evaluate==0.4.0\" tensorboard scikit-learn --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a47849c8-40fb-45f7-a765-b410d8b1c3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement transformer (from versions: none)\n",
      "ERROR: No matching distribution found for transformer\n"
     ]
    }
   ],
   "source": [
    "#%pip install transformer --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3009624b-453b-4481-9db3-98073f387de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertModel, RobertaModel, RobertaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12ae9660-75c6-4867-b36c-80df8a2c758f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550abc5bea154548b337a2658a859929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olgas\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\olgas\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d9f19b413d54ae5b81606d3a5f2a2bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11264f50b06742288b78aae0fefffca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dfc7b19-d0f1-4dd0-97ee-58c40a82ef4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a1fb8132ce40c6ad57435f4e51f1c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51ae73c8-3caa-40ca-9a8c-b286038801b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'here', 'is', 'an', 'example', 'paragraph', 'that', 'we', 'will', 'convert', 'into', 'an', 'em', '##bed', '##ding', '.', '[SEP]']\n",
      "[101, 2182, 2003, 2019, 2742, 20423, 2008, 2057, 2097, 10463, 2046, 2019, 7861, 8270, 4667, 1012, 102]\n",
      "tensor([[  101,  2182,  2003,  2019,  2742, 20423,  2008,  2057,  2097, 10463,\n",
      "          2046,  2019,  7861,  8270,  4667,  1012,   102]])\n",
      "Wall time: 930 µs\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# Text to vectorize\n",
    "text = \"Here is an example paragraph that we will convert into an embedding.\"\n",
    "\n",
    "# Add special tokens for BERT (start and end of sentence)\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "# Tokenize our sentence\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "print(tokenized_text)\n",
    "\n",
    "# Map tokens to their index in the tokenizer vocabulary\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "print(indexed_tokens)\n",
    "\n",
    "# Convert list to torch tensor\n",
    "tokens_tensor  = torch.tensor([indexed_tokens])\n",
    "print(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70b510fd-7412-45a5-a281-9b445f83e484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.05517262 -0.05596118  0.2387126  -0.26662704  0.07532007  0.06179006\n",
      "  0.67365825 -0.04533741 -0.32682377  0.13599311  0.40212578 -0.21838169\n",
      " -0.05768028  0.3261929  -0.22031818  0.39030343  0.08599138 -0.03073616\n",
      "  0.4642036  -0.12418564]\n"
     ]
    }
   ],
   "source": [
    "# Put everything on the GPU if available and run through the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tokens_tensor = tokens_tensor.to(device)\n",
    "model = model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(tokens_tensor)\n",
    "    # The first element of outputs is the last layer of the model, which can be used as embeddings.\n",
    "    embeddings = outputs[0]\n",
    "\n",
    "# Calculate the mean to get sentence vector\n",
    "mean_embeddings = torch.mean(embeddings, dim=1).cpu().numpy()\n",
    "\n",
    "print(mean_embeddings.flatten()[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2aca2c00-1f1b-460c-bb33-67d24f67a3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be3b15fe-9981-4f3c-ab4c-935206a01c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb7d75dae4724d80b44700dd6c3d9768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a84cc0b1f8b429092f8fa5bc5b17293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3dfe8169df44097995b6767edb610b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a38e48e967e64f1ba9c54cd4b8992b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load pre-trained model and tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2Model.from_pretrained('gpt2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b95211b-b260-4e3f-96d4-318771c3e3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text to vectorize\n",
    "text = \"Here is an example paragraph that we will convert into an embedding. it might help me.\"\n",
    "\n",
    "# Tokenize our sentence\n",
    "input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "\n",
    "# Run through the model\n",
    "outputs = model(input_ids)\n",
    "# The first ripprelement of outputs is the last layer of the model, which can be used as embeddings.\n",
    "embeddings = outputs[0]\n",
    "\n",
    "# Calculate the mean to get sentence vector\n",
    "mean_embeddings = torch.mean(embeddings, dim=1).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b703687-35aa-427a-99fe-00a0040e17be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(text):\n",
    "    input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "\n",
    "    # Run through the model\n",
    "    outputs = model(input_ids)\n",
    "    # The first ripprelement of outputs is the last layer of the model, which can be used as embeddings.\n",
    "    embeddings = outputs[0]\n",
    "\n",
    "    # Calculate the mean to get sentence vector\n",
    "    mean_embeddings = torch.mean(embeddings, dim=1).cpu().detach().numpy()\n",
    "    return mean_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b72ce30c-5b14-41c8-8258-a81c5c5041f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4342,   318,   281,  1672,  7322,   326,   356,   481, 10385,   656,\n",
      "          281, 11525, 12083,    13,   340,  1244,  1037,   502,    13])\n",
      "tensor([-0.2551, -0.1230, -0.2618,  ...,  0.1842, -0.0650,  0.2318],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 17, 768])\n",
      "(1, 768)\n"
     ]
    }
   ],
   "source": [
    "print(input_ids.flatten())\n",
    "print(embeddings.flatten())\n",
    "print(embeddings.shape)\n",
    "print(mean_embeddings.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
